---
format: gfm
execute: 
  warning: false
  echo: false
  messae: false
---

# Download the data

```{r}
library(tidyverse)
library(gt)

tibble(
  type = c("CSV", "Stata"),
  links = c(
    "data/processed/adelsvapen_dataset.csv",
    "data/processed/adelsvapen_dataset.zip"
  ),
  logos = c("https://upload.wikimedia.org/wikipedia/commons/4/44/Microsoft_logo.svg",
            "https://cdn.icon-icons.com/icons2/2107/PNG/512/file_type_stata_icon_130148.png")
) %>%
  mutate(
    link = glue::glue("<a href = {links}>
                      <img src='{logos}' width='50' height='50'>
                                   </a>"),
    link_text = glue::glue("<a href = {links}>
                      {type}
                                   </a>"),
    link = purrr::map(link, gt::html),
    link_text = purrr::map(link_text, gt::html)
  ) %>%
  select(link, link_text) %>%
  gt() %>%
  cols_align(columns = c(link, link_text), align = "left") %>% 
  tab_options(column_labels.hidden = TRUE) %>% 
  tab_header(title = md("**Download data**")) %>% 
  as_raw_html(inline_css = TRUE)
```


## Purpose

Scraper of [Adelsvapen](https://www.adelsvapen.com/genealogi/Huvudsida) genealogy website for noble families of Sweden.

## Output

Click [here](https://rawcdn.githack.com/j-jayes/adelsvapen/49945be4674b039499f06050102ec22840f89814/03-processor.html) to see what the data looks like.


```{r}
knitr::include_graphics("images/example_data.PNG")
```

## Planning

This is what the website looks like:

```{r}
knitr::include_graphics("images/home-page.PNG")
```

And these are the pages with the information that we want to get, including:

- Name of the family
- Date of introduction into nobility and extinction
- The first person in the family and their biography
- The biography of their children

Ideally we would want to process this text in such way to keep the bolded names, and extract birth places and dates.

```{r}
knitr::include_graphics("images/abrahamsson.PNG")
```

### Robots.txt

First we check if they have asked us not to scrape the website.

<blockquote>

robots.txt is a standard used by websites to indicate to visiting web crawlers and other web robots which portions of the website they are allowed to visit. This relies on voluntary compliance.

</blockquote>

They have an extensive list of bots they do not allow, but do not forbid us from scraping the `/genealogi` subsection. So as long as we use a good wait time between hits so as not to overwhelm their server, we will be okay!

```{r}
knitr::include_graphics("images/robots-top.PNG")
knitr::include_graphics("images/robots.PNG")
```

### Starting point

We want to get a list of the noble families and a link to their family trees, as shown in the table below:

```{r}
library(tidyverse)
library(gt)

# We have just pulled these in by hand - it wasn't faster to scrape them.
noble_families <- tribble(
  ~family, ~url,
  "Abrahamsson - von Döbeln", "https://www.adelsvapen.com/genealogi/Abrahamsson_-_von_D%C3%B6beln",
  "von Ebbertz - Järnefelt", "https://www.adelsvapen.com/genealogi/Von_Ebbertz_-_J%C3%A4rnefelt",
  "Kafle - Oxehufwud", "https://www.adelsvapen.com/genealogi/Kafle_-_Oxehufwud",
  "Pahl - Sölfvermusköt", "https://www.adelsvapen.com/genealogi/Pahl_-_S%C3%B6lfvermusk%C3%B6t",
  "Tallberg - Östner", "https://www.adelsvapen.com/genealogi/Tallberg_-_%C3%96stner"
)

noble_families %>% 
  mutate(
    link = glue::glue("[link]({url})"),
    link = map(link, gt::md)
  ) %>%
  select(family, link) %>%
  gt() %>%
  cols_align(columns = link, align = c("left")) %>%
  tab_header(title = md("**Noble families of Sweden**")) %>%
  tab_options(column_labels.hidden = TRUE) %>% 
  tab_footnote(md("Source: [Adelsvapen](https://www.adelsvapen.com/)")) %>% 
  as_raw_html(inline_css = TRUE)
```

### Branches

Next we want to scrape the links to the branches of family trees for each family. They look like this:

```{r}
knitr::include_graphics("images/branches.PNG")
```

Ideally we would loop through the list and keep a record of each branch of the family tree with a link to it.

```{r}
#| eval: false
#| echo: true
# let's write a function to do this

library(rvest)

get_branches <- function(url_in) {
  message("Getting branches of family tree from: ", url_in)
  Sys.sleep(5)
  html <- read_html(url_in)

  family_links <- html %>%
    html_nodes("a") %>%
    html_attr("href")

  family_links_filtered <- family_links %>%
    as_tibble() %>%
    rename(branch_url = value) %>%
    # get family links that contain a /genealogi beginning and a number
    filter(
      str_detect(branch_url, "/genealogi/.+\\d"),
      !str_detect(branch_url, "Adelsvapen-Wiki"),
      !str_detect(branch_url, "Special:")
    )
  
  return(family_links_filtered)
}

noble_families_branches <- noble_families %>% 
  mutate(branches = map(url, possibly(get_branches, "failed")))

noble_families_branches %>% 
  unnest(branches) %>% 
  write_rds(here::here("links", "family_links.rds"))
```

So now we have a link to each of the 2,335 branches of the family trees.

A sample of these is shown below in a table

```{r}
family_links <- read_rds(here::here("links", "family_links.rds"))

family_links %>% 
  slice_sample(n  = 20) %>% 
  select(family, branch_url) %>% 
  mutate(branch_url = str_remove(branch_url, "/genealogi/"),
         branch_url = str_replace_all(branch_url, "_", " ")) %>% 
  gt() %>% 
  tab_header(title = md("**Sample of branches**")) %>% 
  cols_label(family = "Noble family",
             branch_url = "Branch name") %>% 
  as_raw_html(inline_css = TRUE)
```

### Information on each branch of family tree

Next we want to get the data from each of these branches, including the title, information about the origin individual, and information on their children.

```{r}
#| eval: false
#| echo: true
# Again lets write a function for this
url_in = "https://www.adelsvapen.com/genealogi/Adlerstr%C3%A5hle_nr_1765"

get_info_from_family <- function(url_in) {
  html <- read_html(url_in)

  fam_abb <- str_remove(url_in, "https://www.adelsvapen.com/genealogi/")

  title <- html %>%
    html_nodes(".title") %>%
    html_text()

  bio <- html %>%
    html_nodes("p") %>%
    html_text() %>%
    str_squish() %>%
    as_tibble() %>%
    rename(info = value) %>%
    filter(str_detect(info, "\\d\\d\\d\\d")) %>%
    nest(bio = everything())

  children <- html %>%
    html_nodes("ul") %>%
    html_text() %>%
    str_squish() %>%
    as_tibble() %>%
    rename(children_bio = value) %>%
    filter(str_detect(children_bio, "\\d\\d\\d\\d")) %>%
    # mutate(tab = 1) %>% 
    nest(children = everything())

  # image
  # img_src <- html %>%
  #   html_node(".image") %>%
  #   html_elements("img") %>%
  #   html_attr("src")
  # 
  # img_url <- img_src %>% str_c("https://www.adelsvapen.com", .)
  # 
  # download.file(img_url, destfile = here::here(glue::glue("scraped_images/{fam_abb}.jpg")), mode = "wb")

  return(tibble(title, bio, children))
}

data <- get_info_from_family(url_in)

data %>% 
  write_rds(here::here("temp", "Abrahamsson.rds"))

data <- read_rds(here::here("temp", "Abrahamsson.rds"))

data %>%
  unnest(bio) %>%
  unnest(children) %>%
  mutate(across(where(is.numeric), as.character)) %>% 
  pivot_longer(everything(), names_to = "Section", values_to = "Text") %>%
  mutate(Section = str_to_title(str_replace(Section, "_", " "))) %>%
  arrange(desc(Section)) %>%
  distinct() %>%
  group_by(Section) %>%
  gt() %>%
  tab_style(
    style = list(
      cell_fill(color = "#191970"),
      cell_text(color = "white")
    ),
    locations = cells_row_groups(groups = everything())
  ) %>%
  tab_header(title = md("**Example of data on individual family branches**")) %>%
  tab_footnote(md("Source: [Adelsvapen](https://www.adelsvapen.com/genealogi/Abrahamsson_nr_1817)")) %>% 
  gtsave(here::here("temp", "Abrahamsson_info.png"))

```

```{r}
#| fig-cap: Abrahamsson 1817 Family information
knitr::include_graphics(here::here("temp", "Abrahamsson_info.png"))
```

### Images of family crest

We can also include the family crest:

```{r}
#| fig-cap: Abrahamsson 1817 Family crest
knitr::include_graphics(here::here("scraped_images", "Abrahamsson_nr_1817.jpg"))
```

## Conclusion

To get the information on each of the family branches, we need to loop through our list of 2,335 branches. This will take some time - at 10 seconds of wait time between each hit - it is just more than 6 hours.

We also need to think about how to structure the data that we scrape before going through the whole scraping process.
